写在最前面：看完这篇文章你将对Shader脚本有一个总体的认识，不再觉得Shader脚本写的是什么鬼。耐住性子看完，你会有所收获得！

------

#### Unity3D Shader分三种

**1.表面着色器**（surface shader）----后台自动为你做的绝大部分的工作，减少了你工作量，并且适合绝大多数需要shader的情况。这是unity所推荐的shader程序，所有新创建的shader其实都是surface shader。
**2.顶点片段着色器**（vertex & fragment shader）----可以让你做更多的效果，但是此shader更难写。你也可以用它做一些底层的工作，比如顶点光照(Vertex lighting，即在每个顶点存储该点的光照信息)。顶点光照对于移动设备很有用（译者注：估计省内存吧）。该shader对于一些需要多通道(multiple passes)的高级渲染效果也很有效。
**3.固定方法的shader**
针对硬件能够执行的基本命令，虽然功能有限，但是速度最快。

通过对图形渲染管线的了解，我们知道图形管线能够识别的只有vertex和fragment两种shader。那为什么有这个surface shader呢？
其实，这个surface shader 是对顶点片段着色器的包装，最终unity引擎还是会把surface shader 转换成vertex & fragment shader。

------

当你写一个shader的时候，你可能得有一些**属性值（properties）**，并且有**一个或多个Subshaders**。具体使用哪个Subshader进行处理取决于你的运行平台。

你应该还要指定一个**Fallback(回滚)** shader，当你的subshader没有一个能运行在你的目标设备上，将使用Fallback shader。

先来看一下unity shader的基本结构（以非表面着色器为例）。



```csharp
Shader "XXX"
{
    Properties       //属性，接受参数
    {
          ....
    }
    SubShader
     {
          [Tag]
          [RenderSetup]
          //以上两个可选内容将用于所有pass中
          pass    //每个pass就是一个完整的渲染流程，越多性能越低
            {
                  [Name]                      //设置后可使pass被其他shader复用
                  [Tag]                       //不同于上面的Tag
                  [RenderSetup]               //与上面的一样
                  CGPROGRAM.....主体代码.....ENDCG  
            }
            [ pass{....} ]
     }
     [ SubShader{针对不同显卡使用的子着色器，可选....} ]
      FallBack "..."
}
```

![img](https://upload-images.jianshu.io/upload_images/3806085-54dc288a3b233362.png?imageMogr2/auto-orient/strip|imageView2/2/w/607/format/webp)

SubShader的Tag类型.png

![img](https://upload-images.jianshu.io/upload_images/3806085-c5de86a3c1b2fae0.png?imageMogr2/auto-orient/strip|imageView2/2/w/598/format/webp)

常见的RenderSetup.png



![img](https://upload-images.jianshu.io/upload_images/3806085-7c7f529803cf20fc.png?imageMogr2/auto-orient/strip|imageView2/2/w/605/format/webp)

pass的Tag类型.png

***每个Subshader都至少有一个通道\***（**pass**）作为数据的输入和输出。你可以使用多个通道（passes）执行不同的操作。一个pass就是一个完整的渲染流程，所以，pass越多渲染性能就会降低。
**另外**，着色器代码可以写在SubShader中（表面着色器的做法），也可以写在pass中（顶点/片元/固定函数着色器的做法）。
Surface shader 不需要写pass,因为surface shader会为我们自动完成pass的编译。

尽管shader最终产生的是二维像素，但是其实这些像素除了保存xy坐标外，本身保存着深度值（即每个像素点上的内容在原先3D场景中离照相机的远近）， 你可以控制是否在你的shader中使用**深度缓存（Z-buffer）**产生一些特效，或者在Pass中使用一些指令决定shader是否可以写入Z-buffer：比如使用ZWrite Off时，任何你输出的东西都不会更新Z-buffer的值，即关闭的Z-Buffer的写入功能。

你在shader代码中的Properties{…}部分定义Shader中的属性值（属性值就是用户传入给shader的数据，比如纹理之类的，然后shader处理这些纹理，产生特效。***注意\*** *Properties（属性值）是所有Subshader代码中的共享的，意味着所有SubShader代码中都可以使用这些属性值*。

属性值（property）定义的形式：



```csharp
_Name(“Displayed Name”,type) = default value[{options}]
```

_Name ： 属性值的名称，是在shader代码内部使用的，区别于下面的Displayed Name，后者是在Inspector 面板上显示的，作为外界（用户）的输入提示。
Displayed Name ：呈现在材质编辑器中的属性值名称，在Inspector面板上显示。

**type 属性值的类型**，包括:



```swift
    Color – 表示纯色，使用了RGBA表示法
    2D – 代表尺寸为2的幂次的纹理(如2,4,8,16…256,512)
    Rect – 代表纹理(texture)，不同于上面的纹理，此处纹理的大小不一定是2的幂次。
    Cube – 用于3d中的cube map，经常提到的天空盒就是使用了cube map。
    Range(min, max) – 在min和max之间的一个值，在面板中可用滑动条改变其值大小。
    Float – 任意一浮点数。
    Vector – 4维向量值，本质就是4个浮点数组成的类型。
   （这些都会在shader的检视面板中被看见且可以调动）
```

![img](https://upload-images.jianshu.io/upload_images/3806085-e2c83399ab5b9f00.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/565/format/webp)

全系列

![img](https://upload-images.jianshu.io/upload_images/3806085-00139bad3c78accc.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/435/format/webp)

Inspector界面

**default value 属性值的初始值**，就相当于你的变量初始化的那个值。



```kotlin
  Color – (red,green,blue,alpha)使用了RGBA这种格式的颜色，alpha指的是透明度– 比如 (1,1,1,1)

  2D/Rect/Cube – 纹理的类型，上面已经介绍过了。初始化值可以使一个空字符串，或者"white", "black", "gray", "bump"(说明此纹理是一个凹凸纹理)

  Float/Range – 这个没啥说的，跟浮点数初始化一样一样的

  Vector – 4维向量，其中4个数均为浮点数 (x,y,z,w)
```

**{ options }** 这里注意了，
*{options} 仅仅用于纹理类型，比如上面提到的2D，Rect，Cube，对于这些类型，如果没有options可填，至少要写一个空的{}，否则编译出错*。
可以使用空格将多个options(选项)分开 ，可用的options（选项）如下:
*TexGen texgenmode：纹理坐标自动生成的方式。*
*可以是ObjectLinear, EyeLinear, SphereMap, CubeReflect, CubeNormal其中之一，这些方式和OpenGL中的纹理坐标生成方式相对应。*
***注意当你写Vertex Function时，纹理坐标产生方式将被忽略。\***

下面举几个属性值写法的例子：
定义了一个半透明（alpha=0.5）效果的红色作为默认颜色值:
`MainColor(“Main Color”,Color)=(1,0,0,0.5)`
定义了一个默认值为白色的纹理:
`_Texture(“Texture”,2D) =”white” {}`

注意属性值的定义末尾处不需添加分号。

### 标签（Tags）

你的表面着色器可以用一个或多个标签(tags)进行修饰。tag本身是一组键值对。这些标签的作用是告诉硬件**何时**去调用你的shader代码。

![img](https://upload-images.jianshu.io/upload_images/3806085-3885b46debd5681d.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/564/format/webp)

注意这里的 Tags

在我们的例子中，我们使用：**Tags {“RenderType” = “Opaque”}**，这意味着当程序去渲染不透明的几何体时，将调用我们的shader，Unity定义了一系列这样的渲染过程。

### Tag中的“RenderType”标签

Unity可以运行时替换符合特定RenderType的所有Shader。Camera.RenderWithShader或者Camera.SetReplacementShader配合使用。Unity内置的RenderType包括：
（1）”Opaque”：绝大部分不透明的物体都使用这个；
（2）”Transparent”：绝大部分透明的物体、包括粒子特效都使用这个；
（3）”Background”：天空盒都使用这个；
（4）”Overlay”：GUI、镜头光晕都使用这个；
（5）还有其他可参考Rendering with Replaced Shaders；用户也可以定义任意自己的RenderType字符串。

### Tag中Queue的类型:



```undefined
  Background – 在所有其他物体渲染之前渲染，被用于天空盒或类似的背景效果。
  Geometry – (默认tags为geometry) – 适用于大多数物体。非透明物体使用这种渲染顺序。
  AlphaTest – 顺利通过alpha测试的像素（alpha-test是指当前像素的alpha小于一定的值就舍弃该像素）使用该渲染顺序。
       单独设置该渲染顺序是因为在所有实体渲染过后，该渲染顺序将对渲染经过alpha测试的物体更有效率。
  Transparent – 该渲染标签所属的物体将在标签为Geometry和AlphaTest之后的物体渲染，并且这些贴着Transparent的所有物体本身是从后往前依次渲染的。任何经过alpha-blended的物体都应该使用该标签
       （alpha-blended是指使用当前像素的alpha作为混合因子，来混合之前写入到缓存中像素值，
        此时注意shader是不能写入深度缓存的，因为如果不关闭写入深度缓存，那么在进行深度检测的时候，它背后的物体本来我们是可以透过它被我们看到的，但由于深度检测时，小于它的深度就被剔除了，从而我们就看不到它后面的物体了）
       ，玻璃和粒子效果比较适合该渲染标签。
  Overlay – 该渲染标签适合覆盖效果，任何最后渲染的效果都可以使用该标签，比如透镜光晕。
```

**有趣的是你可以给这些基本的渲染标签进行加加减减。**
这些预定义的值本质上是一组定义整数，Background = 1000， Geometry = 2000, AlphaTest = 2450， Transparent = 3000，最后Overlay = 4000。（译者注：从此处我们也可以一窥究竟，貌似数值大的后渲染。）这些预设值这对透明物体有很大影响，比如一个湖水的平面覆盖了你用广告牌制作的树，你可以对你的树使用**“Queue”=”Transparent-102”**，这样你的树就会绘制在湖水前面了。（数值小的先渲染，照理半透明的湖面绘制在树的前面，但又因为透明物体的深度写入是关闭的，所以不会覆盖深度缓冲池）

回顾代码、

![img](https://upload-images.jianshu.io/upload_images/3806085-2a77c047cfdf1622.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/564/format/webp)

CGPROGRAM中的才是执行shader的程序块

**pragma surface surf Lambert** 这段代码表示其中surface表示这是一个表面着色器，进行结果输出的函数名称为surf，其使用的*光照模型为Lambert光照模型*。

来看看我们的surf函数



```cpp
void surf (Input IN, inout SurfaceOutput o) //参数为固定结构
{
    o.Albedo = tex2D (_MainTex, IN.uv_MainTex).rgb; 
}
```

很明显我们可以看出，我们返回了o.Albeodo值（并不是surf函数返回，而是SufaceOutput返回） —— 该值是Unity为我们定义的SurfaceOutput结构体中的某个成员。该Albedo表示像素的颜色。下来让我们看看SurfaceOutput具体定义了哪些成员。



```cpp
  struct SurfaceOutput {
       half3 Albedo;      //该像素的颜色值
       half3 Normal;      //该像素的法向量
       half3 Emission;    //该像素的辐射光，辐射光是最简单的一种光，它直接从物体发出并且不受任何光源影响
       half Specular;      //该像素的镜面高光
       half Gloss;         //该像素的发光强度
       half Alpha;         //该像素的透明度
};
```

我们的surf函数的输入是什么呢？



```cpp
struct Input { float2 uv_MainTex; };
```

通过简单地创建结构体，我们告诉系统当我们每次调用surf函数时，获取MainTex在该像素的 *纹理坐标*。
如果我们有第二个纹理叫做—_OtherTexture，我们可以通过在输入结构体中添加下面代码得到它的纹理坐标



```cpp
 struct Input { 
      float2 uv_MainTex;
      float2 uv_OtherTexture; 
};
```

此时对于我们所使用的所有纹理，我们的输入结构体包含一套uv坐标或者一套uv2坐标。
如果我们的shader很复杂并且需要知道像素的其他相关信息，我们就可以将以下变量包含在输入结构体中，以此来查询其他的相关变量。



```cpp
  float3 viewDir – 视图方向( view direction)值。为了计算视差效果（Parallax effects），边缘光照（rim lighting）等，需要包含视图方向（view direction）值。
  float4  with COLOR semantic（比如float4 currentColor，即用户自定义和颜色相关的变量名称） – 每个顶点（per-vertex）颜色的插值。
  float4 screenPos – 为了反射效果，需要包含屏幕空间中的位置信息
  float3 worldPos – 世界空间中的位置
  float3 worldRefl – 世界空间中的反射向量。如果表面着色器(surface shader) 不为SurfaceOutput结构中的Normal赋值，将包含这个参数。
  float3 worldNormal – 世界空间中的法线向量(normal vector)。如果表面着色器(surface shader) 不为SurfaceOutput结构中的Normal赋值，将包含这个参数。
  INTERNAL_DATA – 相对于上面的float3 worldRefl和float3 worldNormal，如果表面着色器为SurfaceOutput结构中的Normal赋值了，将使用该参数。为了获得基于每个顶点法线贴图( per-pixel normal map)的反射向量(reflection vector)需要使用世界反射向量(WorldReflectionVector (IN, o.Normal))，其中o.Normal表示的是切空间的法向量，而非世界坐标系下的法向量。
```

现在我们还有两行代码没有详细讨论：



```undefined
  Sampler2D _MainTex;
```

对每一个属性值，我们定义了属性值区域(Properties Section)，在CG程序中要使用属性值都需要对其进行声明。而Sampler2D _MainTex就是对属性_MainTex的声明，**值得注意的是**CG和Properties中的变量类型并不是一 一对应的。但是在使用中，我们必须保证使用名称一致。

![img](https://upload-images.jianshu.io/upload_images/3806085-0a49464c581f474c.jpg?imageMogr2/auto-orient/strip|imageView2/2/w/641/format/webp)



第一个MainTex表示贴图名，它定义了shader将会用到的属性
第二个uv_MainTex表示输入的uv信息
第三个MainTex是一个Sampler2D(这个Sampler2D，可以理解为引用一个2D Texture)，它引用了Properties中的_MainTex。做的事情就是再次声明并链接了_MainTex，使得接下来的CG程序能够使用这个变量。
第四个surf函数中的MainTex即指代Properties中的_MainTex。

接下来看看我们surf函数中唯一一行代码



```undefined
  o.Albedo = tex2d( _MainTex, IN.uv_MainTex).rgb;
```

tex2d的作用是利用IN.uv_MainTex所代表的uv坐标（注意我们上面指定了uv坐标产生的方式，所以此处的IN.uv_MainTex是自动生成的）对纹理_MainTex进行采样。此处，对于o.Albedo我们只取颜色分量中的rgb三分量。

如果你要设置alpha值的话，可以像下面这样赋值



```undefined
float4 texColor = tex2d( _MainTex, IN.uv_MainTex );
o.Albedo = texColor.rgb;
o.Alpha = texColor.a;
```

**另外**
unity的shader语法中有一个Category命令。当你的shader中多个subshader都要定义相同的代码时，可以同意下载此命令下。
例如：



```cpp
Shader "example" {
Category {
    Fog { Mode Off }
    Blend One One
    SubShader {
        // ...
    }
    SubShader {
        // ...
    }
    // ...
}
}
```

### 问题

**如何选择unity shader种类？**

1. 如果你要和各种光源打交道，用表面着色器会更顺手，但要注意移动平台的性能表现。反之，最好使用顶点/片元着色器。
2. 如果有很多自定义的渲染效果，最好使用顶点/片元着色器。